{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Dense, Flatten, LSTM, GRU, Bidirectional, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\preprocessed.csv').dropna()\n",
    "data = data[((data[\" 'European'\"]==1) | (data[\"'European'\"]==1))]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#glove = gensim.downloader.load('glove-twitter-200')\n",
    "#glove.save(\"glove.model\")\n",
    "glove = KeyedVectors.load(\"glove.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514\n"
     ]
    }
   ],
   "source": [
    "words = list(glove.key_to_index.keys())\n",
    "embeddings_index = {}\n",
    "for word in words:    \n",
    "    coefs = np.asarray(glove[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Reviews_cleaned\"]\n",
    "y = data[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 4798 unikatowych tokenów.\n",
      "Kształt tensora danych: (13483, 7)\n",
      "Kształt tensora etykiet: (13483,)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 7\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Znaleziono {len(word_index)} unikatowych tokenów.\")\n",
    "data_X = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "print(f\"Kształt tensora danych: {data_X.shape}\") \n",
    "print(f\"Kształt tensora etykiet: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10786, 7), (2697, 7), (13483,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Słowa nieznalezione w osadzanym indeksie zostaną zastąpione zerami.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 7, 200)            2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 7, 128)            135680    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,187,841\n",
      "Trainable params: 2,187,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "270/270 [==============================] - 24s 41ms/step - loss: 0.4596 - acc: 0.7967 - val_loss: 0.3957 - val_acc: 0.8258\n",
      "Epoch 2/5\n",
      "270/270 [==============================] - 10s 37ms/step - loss: 0.4057 - acc: 0.8265 - val_loss: 0.3830 - val_acc: 0.8457\n",
      "Epoch 3/5\n",
      "270/270 [==============================] - 10s 36ms/step - loss: 0.3916 - acc: 0.8329 - val_loss: 0.3859 - val_acc: 0.8462\n",
      "Epoch 4/5\n",
      "270/270 [==============================] - 9s 35ms/step - loss: 0.3787 - acc: 0.8401 - val_loss: 0.3801 - val_acc: 0.8452\n",
      "Epoch 5/5\n",
      "270/270 [==============================] - 10s 36ms/step - loss: 0.3667 - acc: 0.8460 - val_loss: 0.3887 - val_acc: 0.8462\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "#model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8946522836814322"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(X_test))\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4632263318170051"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
